{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53fa9cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import io\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "import platform\n",
    "from dotenv import load_dotenv\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ce19768",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_PI = \"\"\"\n",
    "import time\n",
    "\n",
    "def calculate(iterations, param1, param2):\n",
    "    result = 1.0\n",
    "    for i in range(1, iterations+1):\n",
    "        j = i * param1 - param2\n",
    "        result -= (1/j)\n",
    "        j = i * param1 + param2\n",
    "        result += (1/j)\n",
    "    return result\n",
    "\n",
    "start_time = time.time()\n",
    "result = calculate(10_000_000, 4, 1) * 4\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Result: {result:.12f}\")\n",
    "print(f\"Execution Time: {(end_time - start_time):.6f} seconds\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6b20879",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_MATRIX = \"\"\"\n",
    "import time\n",
    "import random\n",
    "\n",
    "def generate_matrix(size):\n",
    "    return [[random.random() for _ in range(size)] for _ in range(size)]\n",
    "\n",
    "def matrix_multiply_without_numpy(size):\n",
    "    matrix_a = generate_matrix(size)\n",
    "    matrix_b = generate_matrix(size)\n",
    "    \n",
    "    result = [[0 for _ in range(size)] for _ in range(size)]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Matrix multiplication\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            for k in range(size):\n",
    "                result[i][j] += matrix_a[i][k] * matrix_b[k][j]\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    sum_value = sum(sum(row) for row in result)\n",
    "    \n",
    "    print(f\"Matrix multiplication of {size}x{size} matrices (no NumPy)\")\n",
    "    print(f\"Result sum: {sum_value:.6f}\")\n",
    "    print(f\"Execution Time: {(end_time - start_time):.6f} seconds\")\n",
    "\n",
    "matrix_multiply_without_numpy(300)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad7260db",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLES = {\n",
    "    \"Pi Calculation\": EXAMPLE_PI,\n",
    "    \"Matrix Multiplication\": EXAMPLE_MATRIX\n",
    "}\n",
    "\n",
    "# Helper functions\n",
    "def write_output(code, file_name):\n",
    "    \"\"\"Write the generated code to a file.\"\"\"\n",
    "    with open(file_name, \"w\") as f:\n",
    "        f.write(code)\n",
    "\n",
    "def system_message_for(language):\n",
    "    \"\"\"Create a system message tailored for the requested language.\"\"\"\n",
    "    return (\n",
    "        f\"You are an assistant that reimplements Python code in high-performance {language.upper()} for an M1 Mac. \"\n",
    "        f\"Respond only with {language.upper()} code; do not explain your work other than occasional comments. \"\n",
    "        \"Pay attention to number types to ensure no overflows and include all necessary packages.\\n\\n\"\n",
    "    )\n",
    "\n",
    "def user_prompt_for(python):\n",
    "    \"\"\"Generate the user prompt.\"\"\"\n",
    "    return (\n",
    "        \"Rewrite this Python code in the requested language with the fastest possible implementation that produces \"\n",
    "        \"identical output in the least time. Use appropriate syntax for the language.\\n\\n\" + python\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24cee18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_python(code):\n",
    "    \"\"\"\n",
    "    Execute Python code dynamically and capture its output.\n",
    "    \"\"\"\n",
    "    output = io.StringIO()\n",
    "    try:\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = output  # Redirect standard output to the StringIO object\n",
    "        start_time = time.time()\n",
    "        exec(code, {\"np\": np, \"time\": time})  # Execute code with minimal context\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "    except Exception as e:\n",
    "        return f\"Error during execution: {str(e)}\"\n",
    "    finally:\n",
    "        sys.stdout = old_stdout  # Restore standard output\n",
    "\n",
    "    result = output.getvalue()\n",
    "    if \"Execution Time:\" not in result:\n",
    "        result += f\"\\nExecution Time: {execution_time:.6f} seconds\"\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4bff4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = \"\"\"\n",
    "import time\n",
    "\n",
    "def calculate(iterations, param1, param2):\n",
    "    result = 1.0\n",
    "    for i in range(1, iterations+1):\n",
    "        j = i * param1 - param2\n",
    "        result -= (1/j)\n",
    "        j = i * param1 + param2\n",
    "        result += (1/j)\n",
    "    return result\n",
    "\n",
    "start_time = time.time()\n",
    "result = calculate(100_000_000, 4, 1) * 4\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Result: {result:.12f}\")\n",
    "print(f\"Execution Time: {(end_time - start_time):.6f} seconds\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98b19562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_code_fences(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Strip code fences and any thinking or extraneous text from the model output.\n",
    "    Returns clean code only.\n",
    "    \"\"\"\n",
    "    # First, try to extract code between fences if they exist\n",
    "    code_pattern = re.compile(r\"```(?:[a-zA-Z0-9_+-]*)\\s*\\n([\\s\\S]*?)\\n```\")\n",
    "    code_match = code_pattern.search(s)\n",
    "    \n",
    "    if code_match:\n",
    "        # If we found code between fences, return just that code\n",
    "        return code_match.group(1).strip()\n",
    "    \n",
    "    # Otherwise, clean up the text more generally\n",
    "    # Remove opening fences with optional language indicators\n",
    "    s = re.sub(r\"```(?:[a-zA-Z0-9_+-]*)\\s*\\n?\", \"\", s)\n",
    "    # Remove closing fences\n",
    "    s = re.sub(r\"\\n?```\\s*$\", \"\", s)\n",
    "    # Remove any thinking sections\n",
    "    s = re.sub(r\"(?i)thinking:|<thinking>[\\s\\S]*?</thinking>\", \"\", s)\n",
    "    # Remove common explanatory text that precedes or follows code\n",
    "    s = re.sub(r\"(?i)^.*?(?:here's|here is|the|implementation|code).*?\\n\", \"\", s)\n",
    "    s = re.sub(r\"(?i)\\n.*?(?:this code|explanation|note:).*?$\", \"\", s)\n",
    "    \n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025381f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_cpp(code):\n",
    "    \"\"\"Compile and execute C++ code.\"\"\"\n",
    "    write_output(strip_code_fences(code), \"optimized.cpp\")\n",
    "    is_windows = platform.system() == \"Windows\"\n",
    "    \n",
    "    try:\n",
    "        # Compile command with optimizations\n",
    "        if is_windows:\n",
    "            compile_cmd = [\"g++\", \"-Ofast\", \"-std=c++17\", \"-o\", \"optimized.exe\", \"optimized.cpp\"]\n",
    "            run_cmd = [\"optimized.exe\"]\n",
    "        else:\n",
    "            compile_cmd = [\"clang++\", \"-Ofast\", \"-std=c++17\", \"-march=native\", \"-o\", \"optimized\", \"optimized.cpp\"]\n",
    "            run_cmd = [\"./optimized\"]\n",
    "            \n",
    "        # Compile\n",
    "        compile_result = subprocess.run(\n",
    "            compile_cmd, check=True, text=True, capture_output=True, shell=is_windows\n",
    "        )\n",
    "        \n",
    "        # Run\n",
    "        start_time = time.time()\n",
    "        run_result = subprocess.run(\n",
    "            run_cmd, check=True, text=True, capture_output=True, shell=is_windows\n",
    "        )\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Add execution time if not included in output\n",
    "        output = run_result.stdout\n",
    "        if \"Execution Time:\" not in output:\n",
    "            output += f\"\\nExecution Time: {(end_time - start_time):.6f} seconds\"\n",
    "        \n",
    "        return output\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"Error during compilation or execution:\\n{e.stderr}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a9aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_java(code):\n",
    "    \"\"\"Compile and execute Java code dynamically.\"\"\"\n",
    "    #  Determine the class name from the code\n",
    "    import re\n",
    "    class_pattern = re.compile(r\"public\\s+class\\s+(\\w+)\")\n",
    "    match = class_pattern.search(code)\n",
    "    \n",
    "    if match:\n",
    "        class_name = match.group(1)\n",
    "    else:\n",
    "        class_name = \"Optimized\"  # Default class name\n",
    "        \n",
    "    file_name = f\"{class_name}.java\"\n",
    "\n",
    "\n",
    "    write_output(strip_code_fences(code), file_name)\n",
    "    \n",
    "    is_windows = platform.system() == \"Windows\"\n",
    "\n",
    "    try:\n",
    "        # Compile the Java code\n",
    "        compile_cmd = [\"javac\", file_name]\n",
    "        subprocess.run(compile_cmd, check=True, text=True, capture_output=True, shell=is_windows)\n",
    "        \n",
    "        # Run the compiled Java program\n",
    "        run_cmd = [\"java\", class_name]\n",
    "        start_time = time.time()\n",
    "        run_result = subprocess.run(run_cmd, check=True, text=True, capture_output=True, shell=is_windows)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Add execution time if not included in output\n",
    "        output = run_result.stdout\n",
    "        if \"Execution Time:\" not in output:\n",
    "            output += f\"\\nExecution Time: {(end_time - start_time):.6f} seconds\"\n",
    "            \n",
    "        return output\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"Error during compilation or execution:\\n{e.stderr}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d22c85a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huggingface_stream(python, language=\"cpp\", model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\"):\n",
    "    \"\"\"Generate code using a HuggingFace model via their Inference API with proper authentication.\"\"\"\n",
    "    from huggingface_hub import InferenceClient\n",
    "    import os\n",
    "\n",
    "    if language not in [\"cpp\", \"java\"]:\n",
    "        raise ValueError(\"Invalid language specified. Choose 'cpp' or 'java'.\")\n",
    "\n",
    "    # Get API key from environment variable or let user provide it\n",
    "    api_token = os.environ.get(\"HF_TOKEN\")\n",
    "    if not api_token:\n",
    "        print(\"Warning: HF_TOKEN environment variable not found. Some models may require authentication.\")\n",
    "        \n",
    "    # Customize prompt for model\n",
    "    system_message = system_message_for(language)\n",
    "    user_message = user_prompt_for(python)\n",
    "    \n",
    "    # Format prompt based on model type (different models expect different formats)\n",
    "    if \"mistral\" in model_name.lower() or \"mixtral\" in model_name.lower():\n",
    "        full_prompt = f\"<s>[INST] {system_message}\\n\\n{user_message} [/INST]\"\n",
    "    elif \"llama\" in model_name.lower():\n",
    "        full_prompt = f\"<s>[INST] {system_message}\\n\\n{user_message} [/INST]\"\n",
    "    elif \"starcoder\" in model_name.lower():\n",
    "        full_prompt = f\"<system>\\n{system_message}\\n</system>\\n\\n<user>\\n{user_message}\\n</user>\\n\\n<assistant>\"\n",
    "    elif \"gemma\" in model_name.lower():\n",
    "        full_prompt = f\"<start_of_turn>system\\n{system_message}<end_of_turn>\\n<start_of_turn>user\\n{user_message}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "    else:\n",
    "        full_prompt = f\"System: {system_message}\\n\\nUser: {user_message}\\n\\nAssistant:\"\n",
    "\n",
    "    try:\n",
    "        # Initialize the client with the API token if available\n",
    "        client = InferenceClient(model_name, token=api_token)\n",
    "        \n",
    "        # Define model-specific parameters\n",
    "        params = {\n",
    "            \"max_new_tokens\": 2048,\n",
    "            \"stream\": True,\n",
    "            \"details\": False,\n",
    "            \"temperature\": 0.2,\n",
    "            \"top_p\": 0.95,\n",
    "        }\n",
    "        \n",
    "        # Add stop sequences based on model type\n",
    "        if \"mistral\" in model_name.lower() or \"mixtral\" in model_name.lower() or \"llama\" in model_name.lower():\n",
    "            params[\"stop_sequences\"] = [\"</s>\"]\n",
    "        \n",
    "        full_response = \"\"\n",
    "        for response in client.text_generation(full_prompt, **params):\n",
    "            full_response += response\n",
    "            yield strip_code_fences(full_response)\n",
    "\n",
    "    except Exception as e:\n",
    "        yield f\"Error using HuggingFace model ({model_name}): {str(e)}\\n\\nPlease check your internet connection or Hugging Face API access.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bfc705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_stream(python, language=\"cpp\"):\n",
    "    \"\"\"Generate code using the Ollama API with streaming.\"\"\"\n",
    "    if language not in [\"cpp\", \"java\"]:\n",
    "        raise ValueError(\"Invalid language specified. Choose 'cpp' or 'java'.\")\n",
    "    \n",
    "    # Set up the prompt for code conversion\n",
    "    system_message = system_message_for(language)\n",
    "    user_message = user_prompt_for(python)\n",
    "    \n",
    "    # Streaming response with Ollama API\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {# change model if needed here\n",
    "        \"model\": \"codellama\",  # Using the codellama model from Ollama\n",
    "        \"prompt\": f\"{system_message}\\n\\n{user_message}\",\n",
    "        \"stream\": False  # Set to True for streaming, False for complete response\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        if payload[\"stream\"]:\n",
    "            # This would handle streaming if needed\n",
    "            full_response = \"\"\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    chunk = response.json()\n",
    "                    if \"response\" in chunk:\n",
    "                        full_response += chunk[\"response\"]\n",
    "                        yield full_response\n",
    "        else:\n",
    "            # Return the full response\n",
    "            result = response.json()\n",
    "            yield result[\"response\"]\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        yield f\"Error connecting to Ollama API: {str(e)}\\n\\nPlease make sure Ollama is running with the llama model.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea896d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepseek_stream(python, language=\"cpp\"):\n",
    "    \"\"\"\n",
    "    Generate code using the DeepSeek model via Ollama API with improved prompting.\n",
    "    \n",
    "    Args:\n",
    "        python (str): Python code to convert  \n",
    "        language (str): Target language (cpp or java)\n",
    "        \n",
    "    Yields:\n",
    "        str: Generated code with proper formatting\n",
    "    \"\"\"\n",
    "    if language not in [\"cpp\", \"java\"]:\n",
    "        raise ValueError(\"Invalid language specified. Choose 'cpp' or 'java'.\")\n",
    "    \n",
    "    # Set up the prompt for code conversion with specific instructions to avoid thinking\n",
    "    system_message = system_message_for(language)\n",
    "    user_message = user_prompt_for(python)\n",
    "    \n",
    "    # Enhanced system prompt to get clean code output\n",
    "    enhanced_system = (\n",
    "        f\"{system_message}\\n\"\n",
    "        \"IMPORTANT: Respond ONLY with clean code. No explanations, no thinking sections, \"\n",
    "        f\"just the complete {language.upper()} implementation. Do not use code fences or ```.\"\n",
    "    )\n",
    "    \n",
    "    # API request\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": \"deepseek-r1\", \n",
    "        \"prompt\": f\"{enhanced_system}\\n\\n{user_message}\",\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        if payload[\"stream\"]:\n",
    "            # This would handle streaming if needed\n",
    "            full_response = \"\"\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    chunk = response.json()\n",
    "                    if \"response\" in chunk:\n",
    "                        full_response += chunk[\"response\"]\n",
    "                        yield strip_code_fences(full_response)\n",
    "        else:\n",
    "            # Return the full response with fences and thinking removed\n",
    "            result = response.json()\n",
    "            yield strip_code_fences(result[\"response\"])\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        yield f\"Error connecting to Ollama API: {str(e)}\\n\\nPlease make sure Ollama is running with the DeepSeek model.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c45c8cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixtral_stream(python, language=\"cpp\"):\n",
    "    \"\"\"Generate code using Mixtral model via Hugging Face.\"\"\"\n",
    "    from huggingface_hub import InferenceClient\n",
    "\n",
    "    if language not in [\"cpp\", \"java\"]:\n",
    "        raise ValueError(\"Invalid language specified. Choose 'cpp' or 'java'.\")\n",
    "\n",
    "    # Customize prompt for Mixtral\n",
    "    system_message = system_message_for(language)\n",
    "    user_message = user_prompt_for(python)\n",
    "    full_prompt = f\"<s>[INST] {system_message}\\n\\n{user_message} [/INST]\"\n",
    "\n",
    "    try:\n",
    "        client = InferenceClient(\"mistralai/Mixtral-8x7B-Instruct-v0.1\")\n",
    "        full_response = \"\"\n",
    "        for response in client.text_generation(\n",
    "            full_prompt,\n",
    "            max_new_tokens=2048,\n",
    "            stream=True,\n",
    "            details=False,\n",
    "            typical_p=0.7,\n",
    "            temperature=0.3,\n",
    "            stop_sequences=[\"</s>\"]\n",
    "        ):\n",
    "            full_response += response\n",
    "            yield full_response\n",
    "\n",
    "    except Exception as e:\n",
    "        yield f\"Error using Mixtral model: {str(e)}\\n\\nPlease check your internet connection or Hugging Face API access.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52c4ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(python, model=\"Ollama\", language=\"cpp\", api_key=None):\n",
    "    \"\"\"\n",
    "    Optimize the given Python code using the specified model and generate the output\n",
    "    in the requested programming language.\n",
    "    \n",
    "    Args:\n",
    "        python (str): Python code to convert\n",
    "        model (str): Model identifier to use\n",
    "        language (str): Target language (cpp or java)\n",
    "        api_key (str): HuggingFace API key (only for HF models)\n",
    "        \n",
    "    Yields:\n",
    "        str: Generated code with proper formatting\n",
    "    \"\"\"\n",
    "    # Map friendly model names to actual model paths for HuggingFace\n",
    "    model_paths = {\n",
    "        \"CodeLlama-7B\": \"codellama/CodeLlama-7b-hf\",\n",
    "        \"StarCoder-1B\": \"bigcode/starcoderbase-1b\", \n",
    "        \"StarCoder-3B\": \"bigcode/starcoderbase-3b\",\n",
    "        \"CodeGemma-2B\": \"google/codegemma-2b\",\n",
    "        \"Gemma-2B\": \"google/gemma-2b\",\n",
    "        \"TinyLlama-1.1B\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "    }\n",
    "    \n",
    "    if model == \"Ollama\":\n",
    "        stream = ollama_stream(python, language=language)\n",
    "    elif model == \"DeepSeek\":\n",
    "        stream = deepseek_stream(python, language=language)\n",
    "    elif model == \"Mixtral-8x7B\":\n",
    "        stream = huggingface_stream(python, language=language, \n",
    "                                    model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\")\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model. Please choose a supported model.\")\n",
    "    for stream_so_far in stream:\n",
    "        yield stream_so_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30dfd16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "css = \"\"\"\n",
    ":root {\n",
    "    --python-color: #3572A5;\n",
    "    --cpp-color: #004482;\n",
    "    --java-color: #B07219;\n",
    "    --background-color: #F7F8FA;\n",
    "    --text-color: #1A202C;\n",
    "    --card-bg: #FFFFFF;\n",
    "    --border-color: #E2E8F0;\n",
    "    --shadow: 0 4px 6px -1px rgba(0,0,0,0.1), 0 2px 4px -1px rgba(0,0,0,0.06);\n",
    "    --primary-font: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;\n",
    "}\n",
    "\n",
    "body {\n",
    "    background-color: var(--background-color);\n",
    "    color: var(--text-color);\n",
    "    margin: 0;\n",
    "}\n",
    "\n",
    ".gradio-container {\n",
    "    font-family: var(--primary-font);\n",
    "    max-width: 1200px;\n",
    "    margin: 0 auto;\n",
    "    padding: 2rem;\n",
    "}\n",
    "\n",
    ".app-header {\n",
    "    text-align: center;\n",
    "    margin-bottom: 2.5rem;\n",
    "    padding: 2rem;\n",
    "    background: linear-gradient(135deg, var(--python-color), var(--cpp-color));\n",
    "    border-radius: 12px;\n",
    "    color: white;\n",
    "    box-shadow: var(--shadow);\n",
    "}\n",
    "\n",
    ".app-header h1 {\n",
    "    margin: 0;\n",
    "    font-size: 2rem;\n",
    "    font-weight: 700;\n",
    "}\n",
    "\n",
    ".app-header p {\n",
    "    margin: 0.5rem 0 0;\n",
    "    opacity: 0.9;\n",
    "}\n",
    "\n",
    ".card {\n",
    "    background: var(--card-bg);\n",
    "    border-radius: 12px;\n",
    "    box-shadow: var(--shadow);\n",
    "    padding: 1.5rem;\n",
    "    margin-bottom: 1.5rem;\n",
    "    border: 1px solid var(--border-color);\n",
    "}\n",
    "\n",
    ".code-box {\n",
    "    border-radius: 8px;\n",
    "    border: 1px solid var(--border-color);\n",
    "    font-family: 'JetBrains Mono', monospace;\n",
    "    position: relative;\n",
    "    resize: vertical;\n",
    "    min-height: 250px;\n",
    "    max-height: 500px;\n",
    "    font-size: 0.9rem;\n",
    "    transition: border-color 0.2s ease;\n",
    "}\n",
    "\n",
    ".code-box:focus-within {\n",
    "    border-color: var(--python-color);\n",
    "}\n",
    "\n",
    ".python-box { border-color: var(--python-color); }\n",
    ".cpp-box { border-color: var(--cpp-color); }\n",
    ".java-box { border-color: var(--java-color); }\n",
    "\n",
    ".output-box {\n",
    "    background-color: var(--card-bg);\n",
    "    border-radius: 8px;\n",
    "    border: 1px solid var(--border-color);\n",
    "    min-height: 100px;\n",
    "    font-family: 'JetBrains Mono', monospace;\n",
    "    font-size: 0.9rem;\n",
    "}\n",
    "\n",
    ".python-result { border-color: var(--python-color); }\n",
    ".cpp-result { border-color: var(--cpp-color); }\n",
    ".java-result { border-color: var(--java-color); }\n",
    "\n",
    ".btn {\n",
    "    border-radius: 8px;\n",
    "    font-weight: 600;\n",
    "    padding: 0.75rem 1.5rem;\n",
    "    border: none;\n",
    "    cursor: pointer;\n",
    "    transition: all 0.2s ease;\n",
    "    font-family: var(--primary-font);\n",
    "}\n",
    "\n",
    ".btn:disabled {\n",
    "    opacity: 0.6;\n",
    "    cursor: not-allowed;\n",
    "}\n",
    "\n",
    ".python-btn { background-color: var(--python-color); color: white; }\n",
    ".cpp-btn { background-color: var(--cpp-color); color: white; }\n",
    ".java-btn { background-color: var(--java-color); color: white; }\n",
    ".compare-btn { \n",
    "    background-color: #2D3748; \n",
    "    color: white; \n",
    "}\n",
    "\n",
    ".btn:hover:not(:disabled) {\n",
    "    transform: translateY(-1px);\n",
    "    box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "    filter: brightness(1.05);\n",
    "}\n",
    "\n",
    ".comparison-table {\n",
    "    width: 100%;\n",
    "    border-collapse: separate;\n",
    "    border-spacing: 0;\n",
    "    background: #F0F4F8;\n",
    "    border-radius: 8px;\n",
    "    overflow: hidden;\n",
    "    box-shadow: var(--shadow);\n",
    "}\n",
    "\n",
    ".comparison-table th, .comparison-table td {\n",
    "    border: none;\n",
    "    padding: 1rem;\n",
    "    color: #1A202C;\n",
    "    text-align: center;\n",
    "}\n",
    "\n",
    ".comparison-table th {\n",
    "    background-color: #CBD5E0; /* Slightly darker gray for header */\n",
    "    color: #1A202C;\n",
    "    font-weight: 600;\n",
    "    text-transform: uppercase;\n",
    "    font-size: 0.85rem;\n",
    "}\n",
    "\n",
    ".comparison-table tr:nth-child(even) {\n",
    "    background-color: #E2E8F0; \n",
    "}\n",
    "\n",
    ".comparison-table tr:nth-child(odd) {\n",
    "    background-color: #F0F4F8;\n",
    "}\n",
    "\n",
    "\n",
    ".copy-btn {\n",
    "    position: absolute;\n",
    "    top: 10px;\n",
    "    right: 10px;\n",
    "    background: var(--card-bg);\n",
    "    border: 1px solid var(--border-color);\n",
    "    border-radius: 6px;\n",
    "    padding: 0.4rem 0.8rem;\n",
    "    cursor: pointer;\n",
    "    font-size: 0.8rem;\n",
    "    font-family: var(--primary-font);\n",
    "    transition: all 0.2s ease;\n",
    "}\n",
    "\n",
    ".copy-btn:hover {\n",
    "    background: #EDF2F7;\n",
    "}\n",
    "\n",
    ".dropdown-container {\n",
    "    display: flex;\n",
    "    gap: 1rem;\n",
    "    margin-bottom: 1.5rem;\n",
    "}\n",
    "\n",
    "@media (max-width: 768px) {\n",
    "    .gradio-container {\n",
    "        padding: 1rem;\n",
    "    }\n",
    "    \n",
    "    .app-header {\n",
    "        padding: 1.5rem;\n",
    "    }\n",
    "    \n",
    "    .card {\n",
    "        padding: 1rem;\n",
    "    }\n",
    "    \n",
    "    .btn {\n",
    "        padding: 0.6rem 1rem;\n",
    "    }\n",
    "    \n",
    "    .dropdown-container {\n",
    "        flex-direction: column;\n",
    "        gap: 0.5rem;\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a05a4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ui():\n",
    "    with gr.Blocks(css=css, theme=gr.themes.Soft()) as ui:\n",
    "        state = gr.State({\"is_running\": False, \"last_copy_id\": None})\n",
    "        \n",
    "        gr.HTML(\"\"\"\n",
    "        <div class=\"app-header\">\n",
    "            <h1>Code Conversion & Performance Suite</h1>\n",
    "            <p>Professional tool for code transformation and runtime analysis</p>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "        \n",
    "        with gr.Row(elem_classes=\"dropdown-container\"):\n",
    "            example_dropdown = gr.Dropdown(\n",
    "                choices=list(EXAMPLES.keys()),\n",
    "                label=\"Example Code\",\n",
    "                value=\"Pi Calculation\",\n",
    "                interactive=True,\n",
    "                scale=1\n",
    "            )\n",
    "            model_dropdown = gr.Dropdown(\n",
    "                choices=[\"Ollama\", \"DeepSeek\", \"Mixtral-8x7B\"],\n",
    "                label=\"AI Model\",\n",
    "                value=\"Ollama\",\n",
    "                interactive=True,\n",
    "                scale=1\n",
    "            )\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(elem_classes=\"card\"):\n",
    "                python_code = gr.Code(\n",
    "                    label=\"Python Source Code\",\n",
    "                    language=\"python\",\n",
    "                    value=EXAMPLES[\"Pi Calculation\"],\n",
    "                    elem_classes=[\"code-box\", \"python-box\"],\n",
    "                    lines=15\n",
    "                )\n",
    "                with gr.Row():\n",
    "                    python_run_btn = gr.Button(\n",
    "                        \"Execute Python\", \n",
    "                        elem_classes=[\"btn\", \"python-btn\"],\n",
    "                        elem_id=\"run-python\"\n",
    "                    )\n",
    "                    convert_cpp_btn = gr.Button(\n",
    "                        \"Convert to C++\", \n",
    "                        elem_classes=[\"btn\", \"cpp-btn\"],\n",
    "                        elem_id=\"convert-cpp\"\n",
    "                    )\n",
    "                    convert_java_btn = gr.Button(\n",
    "                        \"Convert to Java\", \n",
    "                        elem_classes=[\"btn\", \"java-btn\"],\n",
    "                        elem_id=\"convert-java\"\n",
    "                    )\n",
    "                python_output = gr.TextArea(\n",
    "                    label=\"Python Output\",\n",
    "                    elem_classes=[\"output-box\", \"python-result\"],\n",
    "                    lines=5\n",
    "                )\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(elem_classes=\"card\"):\n",
    "                cpp_code = gr.Code(\n",
    "                    label=\"C++ Code\",\n",
    "                    language=\"cpp\",\n",
    "                    elem_classes=[\"code-box\", \"cpp-box\"],\n",
    "                    lines=15\n",
    "                )\n",
    "                cpp_run_btn = gr.Button(\n",
    "                    \"Execute C++\", \n",
    "                    elem_classes=[\"btn\", \"cpp-btn\"],\n",
    "                    elem_id=\"run-cpp\"\n",
    "                )\n",
    "                cpp_output = gr.TextArea(\n",
    "                    label=\"C++ Output\",\n",
    "                    elem_classes=[\"output-box\", \"cpp-result\"],\n",
    "                    lines=5\n",
    "                )\n",
    "            \n",
    "            with gr.Column(elem_classes=\"card\"):\n",
    "                java_code = gr.Code(\n",
    "                    label=\"Java Code\",\n",
    "                    language=\"python\",\n",
    "                    elem_classes=[\"code-box\", \"java-box\"],\n",
    "                    lines=15\n",
    "                )\n",
    "                java_run_btn = gr.Button(\n",
    "                    \"Execute Java\", \n",
    "                    elem_classes=[\"btn\", \"java-btn\"],\n",
    "                    elem_id=\"run-java\"\n",
    "                )\n",
    "                java_output = gr.TextArea(\n",
    "                    label=\"Java Output\",\n",
    "                    elem_classes=[\"output-box\", \"java-result\"],\n",
    "                    lines=5\n",
    "                )\n",
    "        \n",
    "        with gr.Row(elem_classes=\"card\"):\n",
    "            compare_btn = gr.Button(\n",
    "                \"Analyze Performance\", \n",
    "                elem_classes=[\"btn\", \"compare-btn\"],\n",
    "                elem_id=\"compare\"\n",
    "            )\n",
    "            comparison_results = gr.HTML(\n",
    "                label=\"Performance Analysis\",\n",
    "                elem_classes=[\"comparison-table\"]\n",
    "            )\n",
    "        \n",
    "        # JavaScript for copy functionality\n",
    "        gr.HTML(\"\"\"\n",
    "        <script>\n",
    "        async function copyCode(elementId) {\n",
    "            const codeElement = document.querySelector(`#${elementId} textarea`);\n",
    "            const text = codeElement.value;\n",
    "            await navigator.clipboard.writeText(text);\n",
    "            \n",
    "            const btn = document.querySelector(`#${elementId} .copy-btn`);\n",
    "            btn.textContent = 'Copied';\n",
    "            setTimeout(() => btn.textContent = 'Copy', 2000);\n",
    "        }\n",
    "        \n",
    "        document.addEventListener('DOMContentLoaded', () => {\n",
    "            const codeBlocks = document.querySelectorAll('.code-box');\n",
    "            codeBlocks.forEach(block => {\n",
    "                const btn = document.createElement('button');\n",
    "                btn.className = 'copy-btn';\n",
    "                btn.textContent = 'Copy';\n",
    "                btn.onclick = () => copyCode(block.closest('.gradio-container').id);\n",
    "                block.parentElement.appendChild(btn);\n",
    "            });\n",
    "        });\n",
    "        </script>\n",
    "        \"\"\")\n",
    "        \n",
    "        # Event handlers\n",
    "        def update_example(example, state):\n",
    "            state[\"is_running\"] = True\n",
    "            try:\n",
    "                return EXAMPLES[example], state\n",
    "            except KeyError:\n",
    "                return \"Error: Invalid example selected\", state\n",
    "            finally:\n",
    "                state[\"is_running\"] = False\n",
    "        \n",
    "        def convert_code(code, model, target_lang, state):\n",
    "            state[\"is_running\"] = True\n",
    "            try:\n",
    "                if not code.strip():\n",
    "                    return \"Error: Empty code provided\", state\n",
    "                return next(optimize(code, model, target_lang)), state\n",
    "            except Exception as e:\n",
    "                return f\"Error: {str(e)}\", state\n",
    "            finally:\n",
    "                state[\"is_running\"] = False\n",
    "        \n",
    "        def run_code(code, lang, state):\n",
    "            state[\"is_running\"] = True\n",
    "            try:\n",
    "                if lang == \"python\":\n",
    "                    return execute_python(code), state\n",
    "                elif lang == \"cpp\":\n",
    "                    return execute_cpp(code), state\n",
    "                else:\n",
    "                    return execute_java(code), state\n",
    "            except Exception as e:\n",
    "                return f\"Error: {str(e)}\", state\n",
    "            finally:\n",
    "                state[\"is_running\"] = False\n",
    "        \n",
    "        def compare_performance(python_code, cpp_code, java_code, \n",
    "                              python_output, cpp_output, java_output, state):\n",
    "            state[\"is_running\"] = True\n",
    "            try:\n",
    "                def extract_time(output):\n",
    "                    time_pattern = re.compile(r\"Execution Time: (\\d+\\.\\d+) seconds\")\n",
    "                    match = time_pattern.search(output)\n",
    "                    return float(match.group(1)) if match else None\n",
    "                \n",
    "                # Execute if outputs are empty\n",
    "                if not python_output and python_code.strip():\n",
    "                    python_output = execute_python(python_code)\n",
    "                if not cpp_output and cpp_code.strip():\n",
    "                    cpp_output = execute_cpp(cpp_code)\n",
    "                if not java_output and java_code.strip():\n",
    "                    java_output = execute_java(java_code)\n",
    "                \n",
    "                # Extract times\n",
    "                python_time = extract_time(python_output) if python_output else None\n",
    "                cpp_time = extract_time(cpp_output) if cpp_output else None\n",
    "                java_time = extract_time(java_output) if java_output else None\n",
    "                \n",
    "                # Create comparison table\n",
    "                table = \"<table class='comparison-table' style='color: var(--text-color);'>\"\n",
    "                table += \"<tr><th>Language</th><th>Time (seconds)</th><th>Speedup</th></tr>\"\n",
    "                \n",
    "                # Python row\n",
    "                python_display = f\"{python_time:.6f}\" if python_time is not None else \"N/A\"\n",
    "                table += f\"<tr><td>Python</td><td>{python_display}</td><td>1.00x</td></tr>\"\n",
    "                \n",
    "                # C++ row\n",
    "                if cpp_time is not None:\n",
    "                    speedup = python_time / cpp_time if python_time else 0\n",
    "                    table += f\"<tr><td>C++</td><td>{cpp_time:.6f}</td><td>{speedup:.2f}x</td></tr>\"\n",
    "                else:\n",
    "                    table += \"<tr><td>C++</td><td>N/A</td><td>N/A</td></tr>\"\n",
    "                \n",
    "                # Java row\n",
    "                if java_time is not None:\n",
    "                    speedup = python_time / java_time if python_time else 0\n",
    "                    table += f\"<tr><td>Java</td><td>{java_time:.6f}</td><td>{speedup:.2f}x</td></tr>\"\n",
    "                else:\n",
    "                    table += \"<tr><td>Java</td><td>N/A</td><td>N/A</td></tr>\"\n",
    "                \n",
    "                table += \"</table>\"\n",
    "                \n",
    "                # Performance summary\n",
    "                times = [(k, v) for k, v in {\n",
    "                    \"Python\": python_time,\n",
    "                    \"C++\": cpp_time,\n",
    "                    \"Java\": java_time\n",
    "                }.items() if v is not None]\n",
    "                if times:\n",
    "                    fastest = min(times, key=lambda x: x[1])[0]\n",
    "                    table += f\"\"\"\n",
    "                    <div style='margin-top: 1rem; padding: 1rem; background: #EDF2F7; border-radius: 8px;'>\n",
    "                        <p style='margin: 0; font-weight: 600;'>Fastest: {fastest} ({min([t for t in [python_time, cpp_time, java_time] if t is not None]):.6f}s)</p>\n",
    "                    </div>\n",
    "                    \"\"\"\n",
    "                \n",
    "                return table, python_output, cpp_output, java_output, state\n",
    "            except Exception as e:\n",
    "                return f\"Error: {str(e)}\", python_output, cpp_output, java_output, state\n",
    "            finally:\n",
    "                state[\"is_running\"] = False\n",
    "        \n",
    "        # Event bindings\n",
    "        example_dropdown.change(\n",
    "            fn=update_example,\n",
    "            inputs=[example_dropdown, state],\n",
    "            outputs=[python_code, state]\n",
    "        )\n",
    "        \n",
    "        convert_cpp_btn.click(\n",
    "            fn=convert_code,\n",
    "            inputs=[python_code, model_dropdown, gr.State(\"cpp\"), state],\n",
    "            outputs=[cpp_code, state]\n",
    "        )\n",
    "        \n",
    "        convert_java_btn.click(\n",
    "            fn=convert_code,\n",
    "            inputs=[python_code, model_dropdown, gr.State(\"java\"), state],\n",
    "            outputs=[java_code, state]\n",
    "        )\n",
    "        \n",
    "        python_run_btn.click(\n",
    "            fn=run_code,\n",
    "            inputs=[python_code, gr.State(\"python\"), state],\n",
    "            outputs=[python_output, state]\n",
    "        )\n",
    "        \n",
    "        cpp_run_btn.click(\n",
    "            fn=run_code,\n",
    "            inputs=[cpp_code, gr.State(\"cpp\"), state],\n",
    "            outputs=[cpp_output, state]\n",
    "        )\n",
    "        \n",
    "        java_run_btn.click(\n",
    "            fn=run_code,\n",
    "            inputs=[java_code, gr.State(\"java\"), state],\n",
    "            outputs=[java_output, state]\n",
    "        )\n",
    "        \n",
    "        compare_btn.click(\n",
    "            fn=compare_performance,\n",
    "            inputs=[python_code, cpp_code, java_code, \n",
    "                   python_output, cpp_output, java_output, state],\n",
    "            outputs=[comparison_results, python_output, cpp_output, java_output, state]\n",
    "        )\n",
    "        \n",
    "        return ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "012e0e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import sys\n",
    "\n",
    "def execute_python(code):\n",
    "    \"\"\"\n",
    "    Execute Python code dynamically and capture its output.\n",
    "\n",
    "    Args:\n",
    "        code (str): The Python code to execute.\n",
    "\n",
    "    Returns:\n",
    "        str: The captured standard output of the executed code.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If the execution of the code raises an error.\n",
    "    \"\"\"\n",
    "    output = io.StringIO()\n",
    "    try:\n",
    "        sys.stdout = output  # Redirect standard output to the StringIO object\n",
    "        exec(code, {})  # Execute code with an empty global context for safety\n",
    "    except Exception as e:\n",
    "        return f\"Error during execution: {str(e)}\"\n",
    "    finally:\n",
    "        sys.stdout = sys.__stdout__  # Restore standard output\n",
    "\n",
    "    return output.getvalue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd824b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Main function to start the app\n",
    "def main():\n",
    "    ui = create_ui()\n",
    "    ui.launch(debug=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
