{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u82sf_z0tl1M",
    "outputId": "e3c61d63-e6d9-4136-d426-bc5333ec46f2"
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets requests torch peft bitsandbytes transformers trl accelerate sentencepiece wandb matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kjQrY2t3v6fP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from google.colab import userdata\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, set_seed, BitsAndBytesConfig\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import wandb\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44ObvllE02Yz"
   },
   "outputs": [],
   "source": [
    "# os.makedirs(\"utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2h27IJN2v_Ig"
   },
   "outputs": [],
   "source": [
    "BASE_MODEL = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "PROJECT_NAME = \"pricer\"\n",
    "HF_USER = \"rohitsharma77\"\n",
    "\n",
    "# encodings_to_try = ['latin1', 'utf-8', 'cp1252', 'iso-8859-1']\n",
    "\n",
    "# train_loaded = False\n",
    "# for encoding in encodings_to_try:\n",
    "#     try:\n",
    "#         with open(\"train.pkl\", \"rb\") as f:\n",
    "#             train = pickle.load(f, encoding=encoding)\n",
    "#         train_loaded = True\n",
    "#         print(f\"Successfully loaded 'train.pkl' using encoding: {encoding}\")\n",
    "#         break  # Stop if successful\n",
    "#     except UnicodeDecodeError as e:\n",
    "#         print(f\"Error loading 'train.pkl' with encoding {encoding}: {e}\")\n",
    "\n",
    "DATASET_NAME = \"rohitsharma77/lite-data\"\n",
    "MAX_SEQUENCE_LENGTH = 182\n",
    "\n",
    "# Run name for saving the model in the hub\n",
    "\n",
    "RUN_NAME =  f\"{datetime.now():%Y-%m-%d_%H.%M.%S}\"\n",
    "PROJECT_RUN_NAME = f\"{PROJECT_NAME}-{RUN_NAME}\"\n",
    "HUB_MODEL_NAME = f\"{HF_USER}/{PROJECT_RUN_NAME}\"\n",
    "\n",
    "# Hyperparameters for QLoRA\n",
    "\n",
    "LORA_R = 8\n",
    "LORA_ALPHA = 16\n",
    "TARGET_MODULES = [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\n",
    "LORA_DROPOUT = 0.1\n",
    "QUANT_4_BIT = True # change this to quantize to 8 bits (larger)\n",
    "\n",
    "# Hyperparameters for Training\n",
    "\n",
    "EPOCHS = 1 # only 1 is needed more is probably overkill\n",
    "BATCH_SIZE = 1 # increase if more GPU power\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "LR_SCHEDULER_TYPE = 'cosine'\n",
    "WARMUP_RATIO = 0.03\n",
    "OPTIMIZER = \"paged_adamw_32bit\"\n",
    "\n",
    "# note that SAVE_STEPS is how often it will upload to the hub\n",
    "# 2000 so that you get more frequent saves\n",
    "\n",
    "STEPS = 50\n",
    "SAVE_STEPS = 2000\n",
    "# LOG_TO_WANDB = True\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "rUMYtw0FyHCe",
    "outputId": "f69cfa49-9189-493b-952a-264ab9308021"
   },
   "outputs": [],
   "source": [
    "HUB_MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "PiM3YRZlyVZ8",
    "outputId": "c2f9f566-d10e-4519-d9de-e9fa23b262ef"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoAeJOnQzOOh"
   },
   "outputs": [],
   "source": [
    "hf_token = userdata.get('HF_TOKEN')\n",
    "login(hf_token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "7f0cfc3dc80e441890bb4c23a7292b88",
      "769886f4c1214111a6b6e2c3cfe32473",
      "225256b28c06447f8ef469354f78b539",
      "6f9ff3406d3449dd9675ece44389a9fb",
      "2849ac7d3b884ee58d3220c390432151",
      "ff0c98d5a93a4b3d945fb954324a1fc4",
      "de0ad9fc4ca24a648519dc33ca25e22a",
      "62336c7ff8634d13b705e847d2dbda93",
      "c2dc094176364f0a8856285654a99295",
      "b30a162b1dac4d05aa6e2b7e7a6e3837",
      "4d35f1f4dec64db5bc4ea7fbb38af26b",
      "c8769f18d3864254b67816cf3a55ad8a",
      "1bb0dffcc3e54d6d815b9123131c66c0",
      "278313fa90734b79b10fbeb233f93780",
      "8f071f50c13f4a80b26abf0db304b2a6",
      "1dc267d8ffe444eeab67ef18af777c64",
      "4609a9cd5d0f41d1abd175bdd80d1fe3",
      "32805ec98c86488f971e913fff09996d",
      "72f9a8a1fa0d4ecea1b38e5138edadb1",
      "27a41be2dffe454c9d37fa086dfebd90",
      "16babdb8651a438bbe1baf9095a52635",
      "47ad5750c31a450fb9f74d18b66f446b",
      "c58bf80ea69a4699a6f75983a8db42b1",
      "0d9fffa9dc304fc0aca3c9068c1aa026",
      "f26725037a894f8facb672ccb9864265",
      "e01b7112456c49ff9f239fb71a22c176",
      "920d561caaff4fadbac5778c372e425e",
      "af74f166b695497380aa3ed762b91f25",
      "c40afc3aaf434ee4b894e82c3bb134b1",
      "d35af5249ee1426e845e7cedb47fc438",
      "f431254ede1c4864a27fdc5910f24832",
      "e2fb03b1b10f40079709c3b8491d5f2c",
      "84c1f895232247b29c2ab54564d9808b",
      "7da4e32b6cfa4898a65b0683f36e36f1",
      "ee092e0fc6dd47c98202a5c23c579880",
      "8d5cad2cf3654c829f4b44edd3cae62f",
      "99963ee6160f4d728e94524507d95734",
      "6aa32b3b101c47dea87bba407b05d522",
      "77d2442e017e4622ac0183936dbbb84a",
      "a6fdc116b0764e0f89f2709142182455",
      "647ee1e576564a09937375449b88ac24",
      "2a5422da210340cda5a36149d4a3d21c",
      "771cbe6dea174625a07ad14522f8c281",
      "e372258bb496422caad110eda1a0602b",
      "ae06d67222264309bd4fa01c24b512bb",
      "a34d3f39cb1946b0a4e7282d4f726a3b",
      "aea1f18f97434a269ca33f8967d862b3",
      "8862c59d0e2f41d38951a474c9da62e8",
      "3d3887e8d5db463e8366d574c8debf5b",
      "d252d3e4f12a4c97b55c639d3fa49c3a",
      "1f064c4c4226468ca72eeff87684510e",
      "963318e724ce4b879f78c0ee9c836f7e",
      "91e9eab39fc84dbcbea473803570bc07",
      "caa8390cbe8b4efc8dfa9ed5c11848e8",
      "f0db9dbf714d4a49af49f1b6ea11606b"
     ]
    },
    "id": "v7-ey6VFzVRj",
    "outputId": "264a7b12-48c3-4b0b-a8ea-b2b144b6730b"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(DATASET_NAME)\n",
    "train = dataset['train']\n",
    "test = dataset['test']\n",
    "# If you want to reduce the size of train\n",
    "# train = train.select(range(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CfN2HwGOzbIk"
   },
   "outputs": [],
   "source": [
    "# pick the right quantization\n",
    "if QUANT_4_BIT:\n",
    "  quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "  )\n",
    "else:\n",
    "  quant_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_compute_dtype=torch.bfloat16,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477,
     "referenced_widgets": [
      "5eb92a6579d6426487fb5314220120d1",
      "a56fddb075fd456788d52ed4ba7ca9e9",
      "a5338cd5324a4302a2d35369d5995357",
      "01f1af94b632490da764ed5c08cb1ae7",
      "6961623d37c04a528b73ae815900f079",
      "2b208d715c284e73bdfadf0040bfc98b",
      "8d0b103baea14b71822bf834fc1db33f",
      "c52e057a742b4af09d15abcefa68e75b",
      "ae84223824f64372907b8481d53d58cb",
      "b2c37ad5c5d543dfbe97083bba380b6d",
      "37f14e0ce3444727bc9cddd8dbd3d1a2"
     ]
    },
    "id": "6FjGbwCBz2nG",
    "outputId": "f58972e6-9a33-4c55-b8b6-9fa6c51b5d1a"
   },
   "outputs": [],
   "source": [
    "# Load the Tokenizer and the Model\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    quantization_config=quant_config,\n",
    "    device_map=\"cuda:0\",\n",
    ")\n",
    "\n",
    "base_model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "print(f\"Memory footprint: {base_model.get_memory_footprint() / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iuhYVWpV1P-D"
   },
   "outputs": [],
   "source": [
    "# Mask so model focuses on what is required i.e. the price!\n",
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "response_template = \"Price is $\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182,
     "referenced_widgets": [
      "eb55e0d9041149ffb5b02d40acad2b95",
      "ec96038c1291486b874f2ad6b9662e17",
      "6b910f9eb9c8430ca9b3174b3565455f",
      "7b204eeab0a04bca98a83a50650fd009",
      "456a40f4b81045ac88eb6680a5fa2910",
      "31494619e87f41faa0f0804577a0507c",
      "81732fbc3e61414ba6f81773850b0003",
      "92fd82acce254b6d84ae12bf4d0b959c",
      "b4128ade003441adbc476660e31910d3",
      "d2728442f99f440da15cf8aab1b20ed2",
      "1ef50c7f6bde41e48db383dfaf04187f",
      "2157b5a54a0d40aba94c4aa51320b1ed",
      "8dd64b1f45af48178d75110ddd206b22",
      "0a2fd5c40e024d1587b3b202ad1d673b",
      "d23723e7a6cd4228b825645a4122dfec",
      "49f782927e0d49f29b09771b90c45565",
      "19eef11c99e74ca6a080490a2b549fe4",
      "dfd79639b0ca40a4b314b0ae494147ad",
      "015e0d624d9d47b8a5e0959cffb0e7bc",
      "c7df6fdc868c428ea86c0e3b79cdf8a0",
      "2d1de00b2dd6453e8c66de446837f81d",
      "1cd058e3704d4e7cbb5d89dc29172543",
      "bddf2a9b925e4a508cdd85b8b7cf1c5d",
      "c69716da235143a299eae46b2695011f",
      "c37d8b49f0bb4c5baa428b09468af829",
      "bc18f28291614a28a07b7b1c561677d8",
      "ec73b3f52fa749d58a9c805d6cbe3710",
      "8f3ed08320604f8ebd5fbf8a3b47b257",
      "e3a508f96bf34a37afbf7c3712a99c48",
      "23f4a0be13a84c32b316c6653fc61700",
      "631fadc735094649b02389fee0d1211f",
      "ce1360d3dd1c4d74812ff5a1d5cfb336",
      "ed1323a3b0da47d4b2655ab9eed2f9b1",
      "b92df3fb00324eee9961ef05d10fd6a7",
      "290b4c79e298432c8ee329987e57a0aa",
      "7f0b1b5c99f1475a804c84345a29c824",
      "dd15b6441eca4d5bb0300231a8b849e7",
      "f03d15241a974dce9c9b905b395ba487",
      "fda83ea20d5e4d6f8ea18a794fdc384c",
      "d0cfc0b0376f4813997999b09333fee6",
      "e5841350775e44fba040d821ee64fabb",
      "2affde39bfaf493e9072846fc44e7c01",
      "0c3ffcf86d0840c7bec0d5fc8860e173",
      "3f672ab1a6894baebd314be7afed0e5d"
     ]
    },
    "id": "g6bI6w0k7SHj",
    "outputId": "262184a1-7c22-44af-d524-8fb2907cba6a"
   },
   "outputs": [],
   "source": [
    "# First, specify the configuration parameters for LoRA\n",
    "\n",
    "lora_parameters = LoraConfig(\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    r=LORA_R,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=TARGET_MODULES,\n",
    ")\n",
    "\n",
    "# Next, specify the general configuration parameters for training\n",
    "\n",
    "train_parameters = SFTConfig(\n",
    "    output_dir=PROJECT_RUN_NAME,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=1,\n",
    "    eval_strategy=\"no\",\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=OPTIMIZER,\n",
    "    save_steps=SAVE_STEPS,\n",
    "    save_total_limit=10,\n",
    "    logging_steps=STEPS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=LR_SCHEDULER_TYPE,\n",
    "    run_name=RUN_NAME,\n",
    "    max_seq_length=MAX_SEQUENCE_LENGTH,\n",
    "    dataset_text_field=\"text\",\n",
    "    save_strategy=\"steps\",\n",
    "    hub_strategy=\"every_save\",\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=HUB_MODEL_NAME,\n",
    "    hub_private_repo=True\n",
    ")\n",
    "\n",
    "# And now, the Supervised Fine Tuning Trainer will carry out the fine-tuning\n",
    "# Given these 2 sets of configuration parameters\n",
    "# The latest version of trl is showing a warning about labels... ignore\n",
    "\n",
    "fine_tuning = SFTTrainer(\n",
    "    model=base_model,\n",
    "    train_dataset=train,\n",
    "    peft_config=lora_parameters,\n",
    "    args=train_parameters,\n",
    "    data_collator=collator\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uoOtVHqmHJCj",
    "outputId": "ba3b7e29-cfc4-4acf-dae2-06e025307f06"
   },
   "outputs": [],
   "source": [
    "fine_tuning.train()\n",
    "\n",
    "fine_tuning.model.push_to_hub(PROJECT_RUN_NAME, private=True)\n",
    "print(f\"Project to the hub : {PROJECT_RUN_NAME}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
